# D:\AI_Project\talkative-database\query_engine\sql_query_graph.py

from typing import TypedDict

from dotenv import load_dotenv
from langchain import hub
from langchain_community.utilities import SQLDatabase
from langchain_community.tools.sql_database.tool import QuerySQLDatabaseTool
from langgraph.graph import StateGraph
from typing_extensions import Annotated

from data_sources.db_connections import get_database_configs
from query_engine.model import init_llm

# Load environment variables
load_dotenv()

# Init LLM
llm = init_llm()

# Pull LangChain prompt
prompt_template = hub.pull("langchain-ai/sql-query-system-prompt")


# ────────────────────────────
# Define graph state schema
# ────────────────────────────

class State(TypedDict):
    question: str
    query: str
    result: str
    answer: str
    db: SQLDatabase
    db_info: str
    db_name: str


class QueryOutput(TypedDict):
    query: Annotated[str, ..., "Syntactically valid SQL query."]


# ────────────────────────────
# Choose database (SQLite or MSSQL)
# ────────────────────────────

def choose_db(state: State) -> dict:
    question = state["question"].lower()
    db_configs = get_database_configs()

    if "northwind" in question or "sqlite" in question or "employee" in question:
        chosen = "sqlite"
    else:
        chosen = "mssql"

    selected = db_configs.get(chosen)

    if not selected or not selected["db"]:
        # fallback if selected DB is unavailable
        fallback = "sqlite" if chosen == "mssql" else "mssql"
        selected = db_configs.get(fallback)

        if not selected or not selected["db"]:
            raise ValueError("Both MSSQL and SQLite connections failed.")

        chosen = fallback

    return {
        "db": selected["db"],
        "db_info": selected["table_info"],
        "db_name": chosen
    }


# ────────────────────────────
# Generate SQL query using LLM
# ────────────────────────────

def write_query(state: State) -> dict:
    if not state.get("db"):
        raise RuntimeError("No DB selected in write_query()")

    prompt = prompt_template.invoke(
        {
            "dialect": state["db"].dialect,
            "top_k": 5,
            "table_info": state["db_info"],
            "input": state["question"],
        }
    )

    print("\n--- Prompt to LLM ---\n", prompt)

    result = llm.with_structured_output(QueryOutput).invoke(prompt)
    print("\n--- SQL Generated by LLM ---\n", result["query"])

    return {"query": result["query"]}


# ────────────────────────────
# Execute the generated query
# ────────────────────────────

def execute_query(state: State) -> dict:
    execute_query_tool = QuerySQLDatabaseTool(db=state["db"])
    result = execute_query_tool.invoke(state["query"])
    return {"result": result}


# ────────────────────────────
# Generate natural language answer from SQL result
# ────────────────────────────

def generate_answer(state: State) -> dict:
    prompt = (
        "Given the following user question, corresponding SQL query, "
        "and SQL result, answer the user question.\n\n"
        f'Question: {state["question"]}\n'
        f'SQL Query: {state["query"]}\n'
        f'SQL Result: {state["result"]}'
    )

    response = llm.invoke(prompt)
    return {"answer": response.content}


# ────────────────────────────
# Build the LangGraph pipeline
# ────────────────────────────

def answer_question(question: str):
    graph_builder = StateGraph(State)

    graph_builder.add_node("choose_db", choose_db)
    graph_builder.add_node("write_query", write_query)
    graph_builder.add_node("execute_query", execute_query)
    graph_builder.add_node("generate_answer", generate_answer)

    graph_builder.set_entry_point("choose_db")
    graph_builder.add_edge("choose_db", "write_query")
    graph_builder.add_edge("write_query", "execute_query")
    graph_builder.add_edge("execute_query", "generate_answer")

    graph = graph_builder.compile()
    return graph.stream({"question": question})
